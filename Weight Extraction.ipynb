{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Extraction\n",
    "\n",
    "Keras offers a very easy method for extracting the weights and biases from all layers of a trained model. This information is called directly from the trained model using the get_weights() function.\n",
    "\n",
    "This is demonstrated below using the same example as previous notebooks; load pickled files of the MNIST dataset and create a 3 layered MLP with the following architecture;\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "| Layer | No. Input Weights | No. Output Weights | No. Biases | Total Parameters - (In*Out) + Bias |\n",
    "|:-----:|:-----------------:|:------------------:|:----------:|:----------------------------------:|\n",
    "|   1   |        784        |         50         |     50     |               39,250               |\n",
    "|   2   |         50        |         50         |     50     |                2,550               |\n",
    "|   3   |         50        |         10         |     10     |                 510                |\n",
    "\n",
    "\n",
    "Total number of tunable parameters is 42,310.\n",
    "\n",
    "This notebook demonstrates how to extract all these parameters if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "path = '/Users/Nick/Documents/Enrion/Datasets/'\n",
    "\n",
    "X_train = pickle.load( open(os.path.join(path,\"mnist_X_train.pkl\"), \"rb\" ) )\n",
    "X_test = pickle.load( open(os.path.join(path,\"mnist_X_test.pkl\"), \"rb\" ) )\n",
    "y_train = pickle.load( open(os.path.join(path,\"mnist_y_train.pkl\"), \"rb\" ) )\n",
    "y_test = pickle.load( open(os.path.join(path,\"mnist_y_test.pkl\"), \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(input_dim=X_train.shape[1], \n",
    "                output_dim=50, \n",
    "                init='normal', \n",
    "                activation='tanh'))\n",
    "\n",
    "model.add(Dense(input_dim=50, \n",
    "                output_dim=50, \n",
    "                init='normal', \n",
    "                activation='tanh'))\n",
    "\n",
    "model.add(Dense(input_dim=50, \n",
    "                output_dim=y_train.shape[1], \n",
    "                init='normal', \n",
    "                activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-7, momentum=.9, nesterov=False)\n",
    "\n",
    "model.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=50, batch_size=300, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract weights and bias values using the get_weights() function. Each layer is a list of length two, the first list contains a list of lists for containing all weights for each input, the second is a list of all biases.\n",
    "\n",
    "E.g model.layers[0].get_weights()[0] yields a list containing 784 lists each containing 50 values. This represents the 784 input values and the connections to the 50 nodes in the first hidden layer of the network.\n",
    "\n",
    "Show that the number of parameters stored in the variables matches our expected architecture expressed in the above [Table.](#Model-Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Input Values for Input layer is: 784\n",
      "Number of Biases for Input layer is: 50\n",
      "Number of Input Values for Hidden layer is: 50\n",
      "Number of Biases for Hidden layer is: 50\n",
      "Number of Input Values for Output layer is: 50\n",
      "Number of Biases for Output layer is: 10\n"
     ]
    }
   ],
   "source": [
    "layers = {0:'Input',1:'Hidden',2:'Output'}\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"Number of Input Values for {} layer is: {}\".format(layers[i],len(model.layers[i].get_weights()[0])))\n",
    "    print(\"Number of Biases for {} layer is: {}\".format(layers[i],len(model.layers[i].get_weights()[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and store weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_layer_W = model.layers[0].get_weights()[0]\n",
    "input_layer_B = model.layers[0].get_weights()[1]\n",
    "hidden_layer_W = model.layers[1].get_weights()[0]\n",
    "hidden_layer_B = model.layers[1].get_weights()[1]\n",
    "output_layer_W = model.layers[2].get_weights()[0]\n",
    "output_layer_B = model.layers[2].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08820262  0.02000786  0.0489369   0.11204466  0.0933779  -0.0488639\n",
      "  0.04750442 -0.00756786 -0.00516094  0.02052993  0.00720218  0.07271367\n",
      "  0.03805188  0.00608375  0.02219316  0.01668372  0.07470395 -0.01025791\n",
      "  0.01565338 -0.04270479 -0.12764949  0.03268093  0.04322181 -0.03710825\n",
      "  0.11348773 -0.07271829  0.00228793 -0.00935919  0.07663896  0.07346794\n",
      "  0.00774737  0.01890813 -0.04438929 -0.09903982 -0.01739561  0.00781745\n",
      "  0.06151453  0.06011899 -0.01936634 -0.01511514 -0.05242765 -0.0710009\n",
      " -0.08531351  0.09753877 -0.02548261 -0.02190371 -0.06263977  0.03887452\n",
      " -0.08069489 -0.01063701]\n"
     ]
    }
   ],
   "source": [
    "print(input_layer_W[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 Weights connecting the first input value to the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18164791 -0.06975333  0.16924177 -0.0286592  -0.07822143  0.21399206\n",
      " -0.04337408  0.09134258 -0.0532693  -0.01965077]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39250"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_layer_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 Bias values of the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paramters of the model: 42,310\n"
     ]
    }
   ],
   "source": [
    "input_param_count = len(input_layer_W) * len(input_layer_W[0]) + len(input_layer_B)\n",
    "hidden_param_count = len(hidden_layer_W) * len(hidden_layer_W[0]) + len(hidden_layer_B)\n",
    "output_param_count = len(output_layer_W) * len(output_layer_W[0]) + len(output_layer_B)\n",
    "total_param_count = input_param_count + hidden_param_count + output_param_count\n",
    "\n",
    "print('Total paramters of the model: {0:,}'.format(total_param_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

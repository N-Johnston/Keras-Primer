{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - Save Model Architecture and Weights\n",
    "\n",
    "This is a reference notebook to demonstrate the ability to save models built using Keras.\n",
    "\n",
    "For simplicity I have previously pickled the MNIST dataset into the required structure for inputting directly to a Keras MLP model. I will build a simple 2 layered MLP with a softmax output layer. Purpose of this model is solely for testing save functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "path = '/Users/Nick/Documents/Enrion/Datasets/'\n",
    "\n",
    "X_train = pickle.load( open(os.path.join(path,\"mnist_X_train.pkl\"), \"rb\" ) )\n",
    "X_test = pickle.load( open(os.path.join(path,\"mnist_X_test.pkl\"), \"rb\" ) )\n",
    "y_train = pickle.load( open(os.path.join(path,\"mnist_y_train.pkl\"), \"rb\" ) )\n",
    "y_test = pickle.load( open(os.path.join(path,\"mnist_y_test.pkl\"), \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(input_dim=X_train.shape[1], \n",
    "                output_dim=50, \n",
    "                init='normal', \n",
    "                activation='tanh'))\n",
    "\n",
    "model.add(Dense(input_dim=50, \n",
    "                output_dim=50, \n",
    "                init='normal', \n",
    "                activation='tanh'))\n",
    "\n",
    "model.add(Dense(input_dim=50, \n",
    "                output_dim=y_train.shape[1], \n",
    "                init='normal', \n",
    "                activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-7, momentum=.9, nesterov=False)\n",
    "\n",
    "model.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=50, batch_size=300, validation_split=0.1, verbose=1, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score: 94.1%\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test, batch_size = 300, verbose =0)\n",
    "test_acc = np.sum(predictions == y_test) / len(y_test)\n",
    "print(\"Test set accuracy score: {}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Architecture of Model and Weights\n",
    "\n",
    "The skeleton of the model is saved to a JSON file using the model.to_json() function\n",
    "\n",
    "The weights must be saved in a HDF5 file using the h5py library. HDF5 is a data library that stores files as binary data. The h5py package is a Pythonic interface to the HDF5 binary data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_skeleton = model.to_json()\n",
    "open('my_model_architecture.json', 'w').write(model_skeleton)\n",
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Weights\n",
    "\n",
    "Import the model_from_json function from keras.models and declare a name for the loaded model\n",
    "Load the weights into the imported model from the .h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "loaded_model = model_from_json(open('my_model_architecture.json').read())\n",
    "loaded_model.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model must first be compiled prior to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001, decay=1e-7, momentum=.9, nesterov=False)\n",
    "\n",
    "loaded_model.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the loaded model\n",
    "\n",
    "The loaded model should yield the same accuracy as the saved model. We can see below that it does indeed yield 94.1% accuracy on the MNIST test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score from loaded model: 94.1%\n"
     ]
    }
   ],
   "source": [
    "predictions_2 = loaded_model.predict_classes(X_test, batch_size = 300, verbose =0)\n",
    "test_acc_2 = np.sum(predictions_2 == y_test) / len(y_test)\n",
    "print(\"Test set accuracy score from loaded model: {}%\".format(test_acc_2*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
